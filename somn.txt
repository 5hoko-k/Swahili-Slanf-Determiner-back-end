import tensorflow as tf
from tensorflow.keras.preprocessing.sequence import pad_sequences
from tensorflow.keras.models import load_model
from tensorflow.keras.preprocessing.text import tokenizer_from_json
from fastapi import FastAPI, HTTPException, Request, Response
from pydantic import BaseModel
import numpy as np
import pickle
import requests
import aiohttp
from fastapi.responses import JSONResponse
from fastapi.middleware.cors import CORSMiddleware

app = FastAPI()

origins = [
    "http://127.0.0.1:5500/index.html",
    "http://localhost:5173/",
    "http://localhost",
    "http://localhost:5500"
]

# Configure CORS
app.add_middleware(
    CORSMiddleware,
    allow_origins=origins,
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# Load the model
model = load_model('./model.h5')

# Load the tokenizer
with open('tokenizer.pkl', 'rb') as f:
    tokenizer = pickle.load(f)

# Define a request body model using Pydantic
class TextData(BaseModel):
    text: str

class Item(BaseModel):
    name: str


@app.get('/')
async def home():
    return {"message": "Hello World"}

# Define the predict route
@app.post("/predict-sentence")
async def predict(request: Request, data: TextData):
    # Get the text data from the request
    text = data.text

    # Tokenize and pad the text data
    sequence = tokenizer.texts_to_sequences([text])
    sequence = pad_sequences(sequence, maxlen=250)

    # Make the prediction
    prediction = model.predict(sequence)[0][0]
    prediction_label = 'Slang' if prediction >= 0.5 else 'Not Slang'

    # Return the prediction result
    return {"prediction": prediction_label}


@app.get('/predict')
async def trial(request: Request):
    api_url = "https://v1.nocodeapi.com/mbaddy/fbsdk/SzvDUuvbwudDbsEf/firestore/allDocuments?collectionName=MLData"

    async with aiohttp.ClientSession() as session:
        async with session.get(api_url) as response:
            if response.status == 200:
                data = await response.json()  # Parse the JSON data from the response

                # Extract the 'msg' values from the data
                texts = [item['_fieldsProto']['msg']['stringValue'] for item in data]

                # Tokenize and pad the text data
                sequences = tokenizer.texts_to_sequences(texts)
                sequences = pad_sequences(sequences, maxlen=250)

                # Make the predictions
                predictions = model.predict(sequences)
                prediction_labels = ['Slang' if pred >= 0.5 else 'Not Slang' for pred in predictions]

                # Return the prediction results with CORS headers
                results = [{"prediction": label} for label in prediction_labels]
                response.headers['Access-Control-Allow-Origin'] = '*'
                response.headers['Access-Control-Allow-Methods'] = 'GET, POST, OPTIONS'
                response.headers['Access-Control-Allow-Headers'] = 'Content-Type'
                return JSONResponse(content=results, headers=response.headers)

            else:
                # Print an error message if the request was not successful
                print("Error: Failed to retrieve data from the API")
                return {"message": "Error"}